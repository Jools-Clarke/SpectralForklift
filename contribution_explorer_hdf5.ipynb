{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import corner\n",
    "import xarray as xr\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ariel_grid_tb = pd.read_csv(grid_path, delimiter=',',  index_col=0)\n",
    "ariel_grid_tb = ariel_grid_tb.rename(columns={' wavelength (micrometers)':\"wavelength_µm\", \n",
    "                                              ' bin_width (micrometers)':\"bin_width_µm\"})\n",
    "ariel_grid_tb.index.name = None\n",
    "print(ariel_grid_tb.shape)\n",
    "ariel_grid_tb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_tb = pd.read_csv(f'{root_path}/data.csv', delimiter=',', skiprows=1, dtype=str)\n",
    "spectra_tb.drop(index=[0,1], inplace=True)\n",
    "\n",
    "col1 = spectra_tb.columns[0]\n",
    "spectra_tb = spectra_tb.rename(columns={col1:col1[1:]})\n",
    "\n",
    "spectra_tb.columns = spectra_tb.columns.astype(float)\n",
    "spectra_tb = spectra_tb.astype(float)\n",
    "\n",
    "spectra_tb = spectra_tb.iloc[:, ::-1]\n",
    "\n",
    "print(spectra_tb.shape)\n",
    "spectra_tb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tb = pd.read_csv(f'{root_path}/labels.csv', delimiter=',', header=0)\n",
    "labels_tb = labels_tb.rename(columns={'# planet_temp': 'planet_temp_k'})\n",
    "# labels_tb = labels_tb.rename(lambda x: x + '_l', axis='columns') #eh this might mix up columns\n",
    "labels_tb = labels_tb.rename(columns={col: col + '_l' for col in labels_tb.columns})\n",
    "print(labels_tb.shape)\n",
    "labels_tb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_full_tb = pd.read_csv(f'{root_path}/aux_full.csv', delimiter=',', header=0)\n",
    "aux_full_tb = aux_full_tb.rename(columns={'# star_distance': 'star_distance',\n",
    "                                          'star_temperature': 'star_temperature_k',})\n",
    "aux_full_tb = aux_full_tb.rename(columns={col: col + '_a' for col in aux_full_tb.columns})\n",
    "print(aux_full_tb.shape)\n",
    "aux_full_tb.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'{root_path}/contributions_CH4.csv'\n",
    "a = pd.read_csv(file_path, delimiter=',', header=None)\n",
    "a = a.iloc[:, ::-1]\n",
    "a.columns = ariel_grid_tb['wavelength_µm'].values\n",
    "\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = ['CH4', 'CO', 'CO2', 'H2O', 'NH3']\n",
    "species_tb = {}\n",
    "for s in species:\n",
    "    file_path = f'{root_path}/contributions_{s}.csv'\n",
    "    species_tb[s] = pd.read_csv(file_path, delimiter=',', header=None)\n",
    "    species_tb[s] = species_tb[s].iloc[:, ::-1]\n",
    "    species_tb[s].columns = ariel_grid_tb['wavelength_µm'].values\n",
    "    print(species_tb[s].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'ariel_grid_tb shape is {ariel_grid_tb.shape}\\n with headers {ariel_grid_tb.columns}\\n')\n",
    "print(f'spectra_tb shape is {spectra_tb.shape}\\n with headers equal to the column wavelength_µm of ariel_grid_tb\\n')\n",
    "print(f'labels_tb shape is {labels_tb.shape}\\n with headers {labels_tb.columns}\\n')\n",
    "print(f'aux_full_tb shape is {aux_full_tb.shape}\\n with headers {aux_full_tb.columns}\\n')\n",
    "print(f'there are then {len(species_tb)} species_tables stored in a dictionary with keys {species_tb.keys()} which all look like this:')\n",
    "print(f'species_tb shape is {species_tb[\"CH4\"].shape}\\n with headers equal to the column wavelength_µm of ariel_grid_tb\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a sorted list of species from dictionary keys\n",
    "species_order = sorted(species_tb.keys())  # Example: ['CH4', 'CO', 'CO2', 'H2O', 'NH3']\n",
    "\n",
    "\n",
    "# Combine species tables into a 3D array (samples × wavelengths × species)\n",
    "species_data = np.stack([species_tb[sp].values for sp in species_order], axis=-1)\n",
    "\n",
    "# Add 'observed' as the first species\n",
    "species_list = ['observed'] + species_order\n",
    "species_dataset = ['observation'] + ['contribution'] * len(species_order)\n",
    "\n",
    "# Create the Dataset with multi-dimensional species data\n",
    "ds = xr.Dataset(\n",
    "    coords={\n",
    "        'wavelength': ariel_grid_tb['wavelength_µm'].values,\n",
    "        'sample': np.arange(spectra_tb.shape[0]),\n",
    "        'species': species_list  # Add species coordinate\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add spectral bin widths\n",
    "ds['bin_width'] = xr.DataArray(\n",
    "    ariel_grid_tb['bin_width_µm'].values,\n",
    "    dims=['wavelength']\n",
    ")\n",
    "\n",
    "# Reshape observed spectra to include species dimension (for 'observed')\n",
    "spectra_np = spectra_tb.values.reshape(\n",
    "    spectra_tb.shape[0], len(ariel_grid_tb['wavelength_µm'].values), 1\n",
    ")\n",
    "\n",
    "# Combine observed spectra with species data along the species dimension\n",
    "combined_data = np.concatenate([spectra_np, species_data], axis=-1)\n",
    "\n",
    "# Add combined species contributions with the species dimension\n",
    "ds['spectra'] = xr.DataArray(\n",
    "    combined_data,\n",
    "    dims=['sample', 'wavelength', 'species'],\n",
    "        coords={\n",
    "        'species': species_list,  # Same as before\n",
    "    },\n",
    ")\n",
    "\n",
    "# Add planetary parameters\n",
    "for label in labels_tb.columns:\n",
    "    ds[label] = xr.DataArray(\n",
    "        labels_tb[label].values,\n",
    "        dims=['sample'],\n",
    "        attrs={'dataset': 'label'} # Add attribute to distinguish labels from auxiliary parameters\n",
    "    )\n",
    "\n",
    "# Add auxiliary parameters\n",
    "for aux_param in aux_full_tb.columns:\n",
    "    ds[aux_param] = xr.DataArray(\n",
    "        aux_full_tb[aux_param].values,\n",
    "        dims=['sample'],\n",
    "        attrs={'dataset': 'auxiliary'} # Add attribute to distinguish auxiliary parameters from labels\n",
    "    )\n",
    "\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['wavelength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ds['wavelength'], ds['spectra'].sel(sample=0, species='observed'), label='observed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_h2o_spectrum = ds['spectra'].sel(species='H2O').mean(dim='sample')\n",
    "plt.plot(ds['wavelength'], mean_h2o_spectrum, label='mean H2O contribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ds['spectra'].sel(species='observed') \n",
    "y = ds['spectra'].sel(species=['H2O', 'CO2', 'CH4', 'NH3']).sum(dim='species')\n",
    "\n",
    "\n",
    "\n",
    "x = (x - x.min(dim='wavelength')) / (x.max(dim='wavelength') - x.min(dim='wavelength'))\n",
    "x.sel(sample=range(2000)).plot(cmap='Spectral')\n",
    "plt.figure()\n",
    "\n",
    "y = (y - y.min(dim='wavelength')) / (y.max(dim='wavelength') - y.min(dim='wavelength'))\n",
    "y.sel(sample=range(2000)).plot(cmap='Spectral')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "i=0\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# ax.plot(ariel_grid[\"wavelength_µm\"] ,spectra.values[i],'k--', label='spectra')\n",
    "ax.plot(ds['wavelength'], ds['spectra'].sel(sample=i, species='observed'), 'k--', label='observed')\n",
    "\n",
    "# s = ds['species'].values\n",
    "# s = s[s != 'observed']\n",
    "s = (species_values := ds['species'].values)[species_values != 'observed'] # walrus operator!!? I literally never have a real excuse to use these!\n",
    "\n",
    "ax.plot(ds['wavelength'] ,ds['spectra'].sel(sample=i, species=s), label=s)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xscale('log')\n",
    "\n",
    "ax.set_xticks([0.5, 1, 2, 5, 8])\n",
    "ax.set_xticklabels([0.5, 1, 2, 5, 8])\n",
    "\n",
    "ax.set_xlabel('Wavelength (µm)')\n",
    "ax.set_ylabel('Transit depth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (species_values := ds['species'].values)[species_values != 'observed'] # walrus operator!!? I literally never have a real excuse to use these!\n",
    "num_plots = 25\n",
    "n_rows, n_cols = 5, 5\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 10), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.plot(ds['wavelength'], ds['spectra'].sel(sample=i, species='observed'), 'k--', label='observed')\n",
    "    \n",
    "    ax.plot(ds['wavelength'] ,ds['spectra'].sel(sample=i, species=s), label=s)\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "axes[0].legend()\n",
    "\n",
    "ax.set_xticks([0.5, 1, 2, 5, 8])\n",
    "ax.set_xticklabels([0.5, 1, 2, 5, 8])\n",
    "\n",
    "fig.supxlabel('Wavelength (µm)')\n",
    "fig.supylabel('Transit depth')\n",
    "fig.tight_layout()\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ds['wavelength'], ds['spectra'].sel(species='H2O').values[:1000].T)\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1,6):\n",
    "    plt.plot(ds[\"wavelength\"], np.power((ds['spectra'].sel(species='H2O').values[:1000].T),(1/n)))\n",
    "    plt.xscale('log')\n",
    "    plt.title(f'{n}th root, spead {np.power((ds['spectra'].sel(species='H2O').values[:1000].T),(1/n)).std()/np.power((ds['spectra'].sel(species='H2O').values[:1000].T),(1/n)).mean():.4f}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlog the log values in ds by 10^val\n",
    "ds_natural = ds.copy()\n",
    "for var in ds_natural.data_vars:\n",
    "    if 'log_' in var:\n",
    "        new_var = var.replace('log_', '')\n",
    "        ds_natural = ds_natural.rename_vars({var: new_var})\n",
    "        ds_natural[new_var] = np.power(10, ds_natural[new_var])\n",
    "\n",
    "ds_natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (species_values := ds['species'].values)[species_values != 'observed'] # walrus operator!!? I literally never have a real excuse to use these!\n",
    "\n",
    "# Create a boolean mask for samples where at least one value in `spectra` is non-zero\n",
    "sample_mask_w_contribs = ds['spectra'].sel(species=s).sum(dim=['wavelength', 'species']) != 0\n",
    "ds_c = ds.sel(sample = sample_mask_w_contribs)\n",
    "ds_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of parameters to plot (excluding `spectra`)\n",
    "parameters = [var for var in ds.data_vars if var != \"spectra\" and var != \"wavelength\" and var != \"bin_width\"]\n",
    "print(parameters)\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(lp:=len(parameters), 1, figsize=(8, lp * 2), constrained_layout=True)\n",
    "if lp == 1:\n",
    "    axes = [axes]  # Ensure axes is iterable when there's only one parameter\n",
    "\n",
    "for ax, param in zip(axes, parameters):\n",
    "    \n",
    "    data = ds_c[param].values\n",
    "    ax.hist(data.flatten(), bins=50, alpha=0.7, histtype=\"step\", color=\"black\", linewidth=1.5)\n",
    "\n",
    "    ax.axvline(dm:=data.mean(), color=\"black\", linestyle=\"-\", label=\"Mean\") \n",
    "    ax.axvline(dm + (dstd := data.std()), color=\"green\", linestyle=\"--\", label=\"1 Std. Dev.\")\n",
    "    ax.axvline(dm - dstd, color=\"green\", linestyle=\"--\")\n",
    "    ax.axvline(dm + 2 * dstd, color=\"orange\", linestyle=\"-.\", label=\"2 Std. Dev.\")\n",
    "    ax.axvline(dm - 2 * dstd, color=\"orange\", linestyle=\"-.\") \n",
    "    ax.axvline(dm + 3 * dstd, color=\"red\", linestyle=\":\", label=\"3 Std. Dev.\") \n",
    "    ax.axvline(dm - 3 * dstd, color=\"red\", linestyle=\":\")\n",
    "\n",
    "    ax.set_xlabel(param)\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "    ax.set_xlim(data.min(), data.max())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [var for var in ds.data_vars if var != \"spectra\" and var != \"wavelength\" and var != \"bin_width\"]\n",
    "ds[parameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tolerance (e.g., within 10% of the mean)\n",
    "abundance_tolerance = 1e-2\n",
    "no_tolerance = 1e16\n",
    "\n",
    "tolerance = {\n",
    "    'planet_temp_k_l':    no_tolerance,\n",
    "    'log_H2O_l':          no_tolerance,\n",
    "    'log_CO2_l':          no_tolerance,\n",
    "    'log_CH4_l':          abundance_tolerance,\n",
    "    'log_CO_l':           no_tolerance,\n",
    "    'log_NH3_l':          no_tolerance,\n",
    "    'star_distance_a':    no_tolerance,\n",
    "    'star_mass_kg_a':     no_tolerance,\n",
    "    'star_radius_m_a':    no_tolerance,\n",
    "    'star_temperature_k_a':no_tolerance,\n",
    "    'planet_mass_kg_a':   no_tolerance,\n",
    "    'planet_orbital_period_a':no_tolerance,\n",
    "    'planet_distance_a':  no_tolerance,\n",
    "    'planet_radius_m_a':  no_tolerance,\n",
    "    'planet_surface_gravity_a':no_tolerance,\n",
    "            }\n",
    "tolerance_ds = xr.Dataset(tolerance)\n",
    "\n",
    "targets = {\n",
    "    'planet_temp_k_l': 1197.8374538093958,\n",
    "    'log_H2O_l':-5.994919167786353,\n",
    "    'log_CO2_l': -6.499649943854283,\n",
    "    'log_CH4_l': -4,#-6.001007899837979,\n",
    "    'log_CO_l': -4.496589021501109,\n",
    "    'log_NH3_l': -6.491720080880544,\n",
    "    'star_distance_a': 568.2065020332558,\n",
    "    'star_mass_kg_a': 2.0357949035406833e+30,\n",
    "    'star_radius_m_a': 855078079.4802036,\n",
    "    'star_temperature_k_a': 5672.084205905214,\n",
    "    'planet_mass_kg_a': 1.1245086149027514e+27,\n",
    "    'planet_orbital_period_a': 24.335250716885003,\n",
    "    'planet_distance_a': 0.11941006826573485,\n",
    "    'planet_radius_m_a': 44984908.31604669,\n",
    "    'planet_surface_gravity_a': 16.67067211510088\n",
    "}\n",
    "targets_ds = xr.Dataset(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the mean for all parameters\n",
    "# mean_planet = ds[parameters].mean(dim=\"sample\")\n",
    "\n",
    "# Compute the relative difference for all parameters and check if within tolerance\n",
    "relative_diff = np.abs(np.abs(ds_c[parameters]) - np.abs(targets_ds)) / np.abs(targets_ds)\n",
    "within_tolerance = (relative_diff <= tolerance_ds).to_array().all(dim=\"variable\")\n",
    "\n",
    "# Use the mask to subset the dataset\n",
    "reduced_ds = ds_c.sel(sample=within_tolerance)\n",
    "\n",
    "# Print or inspect the resulting subset dataset\n",
    "reduced_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of parameters to plot (excluding `spectra`)\n",
    "parameters = [var for var in ds_c.data_vars if var != \"spectra\" and var != \"wavelength\" and var != \"bin_width\"]\n",
    "print(parameters)\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(len(parameters), 1, figsize=(8, len(parameters) * 2), constrained_layout=True, dpi=500)\n",
    "if len(parameters) == 1:\n",
    "    axes = [axes]  # Ensure axes is iterable when there's only one parameter\n",
    "\n",
    "for ax, param in zip(axes, parameters):\n",
    "    data = ds_c[param].values\n",
    "    \n",
    "    ax.hist(data.flatten(), bins=50, alpha=0.7, histtype=\"step\", color=\"black\", linewidth=1.5, label = \"all data\")\n",
    "\n",
    "    ax.axvline(data.mean(), color=\"black\", linestyle=\"-\", label=\"Mean\") \n",
    "    ax.axvline(data.mean() + data.std(), color=\"green\", linestyle=\"--\", label=\"1 Std. Dev.\")\n",
    "    ax.axvline(data.mean() - data.std(), color=\"green\", linestyle=\"--\")\n",
    "    ax.axvline(data.mean() + 2 * data.std(), color=\"orange\", linestyle=\"-.\", label=\"2 Std. Dev.\")\n",
    "    ax.axvline(data.mean() - 2 * data.std(), color=\"orange\", linestyle=\"-.\") \n",
    "    ax.axvline(data.mean() + 3 * data.std(), color=\"red\", linestyle=\":\", label=\"3 Std. Dev.\") \n",
    "    ax.axvline(data.mean() - 3 * data.std(), color=\"red\", linestyle=\":\")\n",
    "\n",
    "    data_sub = reduced_ds[param].values\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.hist(data_sub.flatten(), bins=30, alpha=1, color=\"blue\", linewidth=1.5, label=\"mean subset\")\n",
    "\n",
    "    ax.set_xlabel(param)\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "    ax.set_xlim(data.min(), data.max())\n",
    "axes[0].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (species_values := reduced_ds['species'].values)[species_values != 'observed'] # walrus operator!!? I literally never have a real excuse to use these!\n",
    "num_plots = 5\n",
    "n_rows, n_cols = 3, 2\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 6), dpi=500)\n",
    "axes = axes.flatten()\n",
    "\n",
    "fig.suptitle(f'Fixed log_CH4 at {reduced_ds[\"log_CH4_l\"].mean().values:.2f} {r'$\\pm$'} {tolerance_ds[\"log_CH4_l\"].values*100:.0f}%')\n",
    "\n",
    "for i, ax in enumerate(axes[:num_plots]):\n",
    "    # ax.plot(reduced_ds['wavelength'] ,reduced_ds['spectra'].sel(species=s[i]).mean(dim='sample'), label=s[i])\n",
    "    # ax.fill_between(reduced_ds['wavelength'], \n",
    "    #                 (rdsm:= (rds := reduced_ds['spectra'].sel(species=s[i])).mean(dim='sample')) - (rdss := rds.std(dim='sample')),\n",
    "    #                 rdsm + rdss,\n",
    "    #                 alpha=0.2)\n",
    "    ax.plot(reduced_ds['wavelength'], \n",
    "            reduced_ds['spectra'].sel(species=s[i]).prod(dim='sample'), \n",
    "            'k-',\n",
    "            label=f'product {s[i]}')\n",
    "    \n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(reduced_ds['wavelength'], \n",
    "            reduced_ds['spectra'].sel(species=s[i]).mean(dim='sample'), \n",
    "            'r--',\n",
    "            label=f'mean {s[i]}')\n",
    "    ax2.tick_params(axis='y', colors='red')\n",
    "    \n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    # ax.set_ylabel(s[i])\n",
    "\n",
    "    ax.set_xticks([0.5, 1, 2, 5, 8])\n",
    "    ax.set_xticklabels([0.5, 1, 2, 5, 8])\n",
    "    # create one legend for all twin axis\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax.legend(lines + lines2, labels + labels2, loc='best')\n",
    "    \n",
    "\n",
    "axes[-1].axis('off')\n",
    "\n",
    "fig.supxlabel('Wavelength (µm)')\n",
    "fig.supylabel('Transit depth')\n",
    "fig.tight_layout()\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets save the dataset we have created into a netcdf file\n",
    "\n",
    "ds.to_netcdf('ariel_data.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and load it back into xarray and verify it is the same\n",
    "\n",
    "ds2 = xr.open_dataset('ariel_data.nc')\n",
    "ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2.equals(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now save the dataset into a hdf5 file\n",
    "\n",
    "ds.to_netcdf('ariel_data.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3 = xr.open_dataset('ariel_data.hdf5')\n",
    "ds3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3.equals(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds_c = xr.open_dataset('contribution_22_checkpoint_backup_10830.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1090\n",
    "\n",
    "for s in ds_c['species'].values:\n",
    "    plt.errorbar(x = ds_c['wavelength'],\n",
    "                y = ds_c['contributions'].loc[dict(sample=n, species=s)],\n",
    "                xerr=ds_c['bin_width']/2,\n",
    "                yerr=ds_c['noise'].sel(sample = n),\n",
    "                fmt=' ', color='lightgrey')\n",
    "    plt.plot(ds_c['wavelength'],\n",
    "         ds_c['contributions'].loc[dict(sample=n, species=s)],\n",
    "           label=s)\n",
    "    \n",
    "plt.plot(ds_c['wavelength'],\n",
    "         ds_c['clean_forward_model'].loc[dict(sample=n)], label='Full Model', color='black')\n",
    "\n",
    "plt.errorbar(x = ds_c['wavelength'],\n",
    "            y = ds_c['spectrum'].sel(sample=n),\n",
    "            xerr=ds_c['bin_width']/2,\n",
    "            yerr=ds_c['noise'].sel(sample=n),\n",
    "            fmt=' ', color='lightgrey')\n",
    "plt.plot(ds_c['wavelength'], \n",
    "         ds_c['spectrum'].sel(sample=n), \n",
    "        \"--k\", label='Data', )\n",
    "\n",
    "plt.xlabel('Wavelength (µm)')\n",
    "plt.ylabel('Transit Depth')\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARIEL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
